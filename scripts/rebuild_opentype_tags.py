import argparse
import io
import os
import pathlib
import re
import urllib.request

repoDir = pathlib.Path(__file__).resolve().parent.parent


def parse(data):
    start = data.find("<tbody>")
    end = data.find("</tbody>")
    data = data[start + 7 : end]
    for chunk in re.findall(r"<tr>.+?</tr>", data, re.DOTALL):
        fields = re.findall(r"<td>(.+?)</td>", chunk, re.DOTALL)
        parsedFields = []
        for field in fields:
            field = field.split("<br>")[0]
            m = re.search(r'href="(.+?)"', field)
            if m is not None and m.group(1) != "#foot":
                parsedFields.append(m.group(1))
            tagParts = field.split("'")
            if len(tagParts) >= 2:
                parsedFields.append(tagParts[1].replace("&nbsp;", " "))
            else:
                parsedFields.append(field)
        if parsedFields:
            yield parsedFields


def formatFeatures(data, baseURL, outFile):
    print("// prettier-ignore", file=outFile)
    print("export const features = {", file=outFile)
    print("  // tag, [friendly name, documentation URL]", file=outFile)
    for link, tag, friendlyName in data:
        if tag == "cv01":
            tags = [f"cv{i:02d}" for i in range(1, 100)]
        elif tag == "ss01":
            tags = [f"ss{i:02d}" for i in range(1, 21)]
        else:
            tags = [tag]
        for tag in tags:
            print(f"  {tag!r}: [{friendlyName!r}, {baseURL + link!r}],", file=outFile)
    print("}", file=outFile)


def formatScripts(data, outFile):
    print("// prettier-ignore", file=outFile)
    print("export const scripts = {", file=outFile)
    print("  // tag, friendly name", file=outFile)
    duplicates = {}
    for i, (friendlyName, tag, *_) in enumerate(data):
        if tag in duplicates:
            duplicates[tag] = duplicates[tag] + ", " + friendlyName
            data[i] = (None, None)  # skip
        else:
            duplicates[tag] = friendlyName
    for _, tag, *_ in data:
        if tag is None:
            continue
        friendlyName = duplicates[tag]
        print(f"  {tag!r}: {friendlyName!r},", file=outFile)
    print("};", file=outFile)


def formatLanguages(data, outFile):
    print("// prettier-ignore", file=outFile)
    print("export const languages = {", file=outFile)
    print("  // tag, friendly name", file=outFile)
    for friendlyName, *fields in data:
        tag = fields[0]
        if len(tag) < 4:
            tag += (4 - len(tag)) * " "
        assert len(tag) == 4, tag
        # if len(fields) == 2:
        #     isoCodes = [isoCode.strip() for isoCode in fields[1].split(",")]
        # elif len(fields) == 1:
        #     # This happens for Bible Cree, Garshuni, Moroccan, Nagari and Yi Classic,
        #     # where the ISO code field is empty
        #     isoCodes = []
        # else:
        #     # This happens in three cases: APPH, IPPH and UPPH, where the page
        #     # doesn't provide explicit ISO codes but links to further info
        #     isoCodes = []
        # t = [friendlyName] + isoCodes
        print(f"  {tag!r}: {friendlyName!r},", file=outFile)
    print("};", file=outFile)


def readOpenTypeTags():
    # https://learn.microsoft.com/en-us/typography/opentype/spec/featurelist
    # https://learn.microsoft.com/en-us/typography/opentype/spec/scripttags
    # https://learn.microsoft.com/en-us/typography/opentype/spec/languagetags

    outFile = io.StringIO()

    baseURL = "https://learn.microsoft.com/en-us/typography/opentype/spec/"

    pages = []
    print(f"// Generated by {os.path.basename(__file__)}", file=outFile)
    print("// Scraped from:", file=outFile)
    for page in ["featurelist", "scripttags", "languagetags"]:
        url = baseURL + page
        print(f"// {url}", file=outFile)
        with urllib.request.urlopen(url) as fp:
            html = fp.read().decode("utf-8", errors="replace")
        pages.append(html)

    for html in pages:
        print(file=outFile)
        parsed = list(parse(html))
        if "<title>Registered features" in html:
            formatFeatures(parsed, baseURL, outFile)
        elif "<title>Script tags" in html:
            formatScripts(parsed, outFile)
        elif "<title>Language system tags" in html:
            formatLanguages(parsed, outFile)
        else:
            assert 0, "huh."

    return outFile.getvalue()


def rebuildOpenTypeTags(check=False):
    openTypeTagsSourcePath = (
        repoDir / "src-js" / "fontra-core" / "src" / "opentype-tags.js"
    )

    openTypeTags = readOpenTypeTags()

    if check:
        oldData = openTypeTagsSourcePath.read_text(encoding="utf-8")
        if openTypeTags != oldData:
            raise ValueError("new source differs from old source")
    else:
        openTypeTagsSourcePath.write_text(openTypeTags, encoding="utf-8")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--check", action="store_true", default=False)
    args = parser.parse_args()

    rebuildOpenTypeTags(check=args.check)
